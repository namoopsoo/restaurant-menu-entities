{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c4c127-3d0d-40b3-bb72-15dce1cc8219",
   "metadata": {},
   "source": [
    "# 2024-06-15\n",
    "So yea initially, I started just with a pipeline,  like\n",
    "\n",
    "```python\n",
    "from transformers import pipeline, BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load Hugging Face pipeline for zero-shot classification\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "```\n",
    "\n",
    "then I was reading through Jake's article, [here](https://jaketae.github.io/study/zero-shot-classification/), realizing ok the pipeline is an abstraction and you can access the raw NLI output entailment logits, `entailement, neutral, contradiction`. \n",
    "\n",
    "So cool, let me try this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682ab2de-4416-472e-86b6-35d0f817bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff87f8f-8ab4-4fa3-8fc3-a3f55434e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "\n",
    "model_name = \"facebook/bart-large-mnli\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForSequenceClassification.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6946a3fb-65c2-4c8a-b959-e56b461b9425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise = \"I am looking for a physical therapist who specializes in sports injuries, close by\"\n",
    "\n",
    "hypothesis = \"this text is about something that is relatively near\"\n",
    "\n",
    "tokens = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "outputs = model(**tokens)\n",
    "outputs.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97ea5ae-c5a4-48fb-b6cc-93e6c2f4a198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b69bfe8-d051-41f5-aa2d-a638c7a19c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5674,  0.0570,  2.5532]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7056994-eb27-4929-b0a6-9959f592dda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.5674, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0570, grad_fn=<SelectBackward0>),\n",
       " tensor(2.5532, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(contradiction, neutral, entailment) = float(logits[0][0]), f(logits[0][1]), logits[0][2]\n",
    "(contradiction, neutral, entailment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0e6d75-9cae-4276-8ef7-947b8cfacdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensor(-2.5670, grad_fn=<RoundBackward1>)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.round(logits[0][0], decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8eee154-844e-4a87-9468-665de0373be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensor([[-2.5700,  0.0600,  2.5500]], grad_fn=<RoundBackward1>)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{torch.round(logits, decimals=2)}\" # .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb87bc4c-2965-484c-aeac-6af4fba57135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0055, 0.0757, 0.9188]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = logits.softmax(dim=1) ; probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edc66814-4831-42a6-9732-969b4d242b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.567\n",
      "0.005\n"
     ]
    }
   ],
   "source": [
    "print(f\"{logits[0][0]:.3f}\")\n",
    "print(f\"{probs[0][0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9521c6-5df5-4d44-b210-6a91edd75909",
   "metadata": {},
   "source": [
    "Thinking about negations hmm, maybe last time I was trying to add a negation into the \"class\" , aka, the premise. That was not working. Maybe this time, let's just stick to letting the neutrality, entailment, contradiction, to speak instead.\n",
    "\n",
    "And an idea, if this doesn't work then yea maybe we'll need something rule based. or also compare to what a sophisticated high order model can say about the statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f47c3213-f1de-49d3-a877-430677114d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close by\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.01', 'neutral: 0.08', 'entailment: 0.92']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close by\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.02', 'neutral: 0.59', 'entailment: 0.39']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close by\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.01', 'neutral: 0.17', 'entailment: 0.82']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close by\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.00', 'neutral: 0.12', 'entailment: 0.88']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.24', 'neutral: 0.55', 'entailment: 0.21']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.03', 'neutral: 0.65', 'entailment: 0.32']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.05', 'neutral: 0.39', 'entailment: 0.56']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.06', 'neutral: 0.39', 'entailment: 0.55']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, nearby\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.00', 'neutral: 0.05', 'entailment: 0.95']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, nearby\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.03', 'neutral: 0.56', 'entailment: 0.41']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, nearby\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.01', 'neutral: 0.14', 'entailment: 0.85']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, nearby\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.00', 'neutral: 0.10', 'entailment: 0.89']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, near me\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.01', 'neutral: 0.11', 'entailment: 0.88']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, near me\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.03', 'neutral: 0.57', 'entailment: 0.40']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, near me\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.01', 'neutral: 0.14', 'entailment: 0.85']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, near me\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.00', 'neutral: 0.10', 'entailment: 0.90']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, in Manhattan\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.04', 'neutral: 0.43', 'entailment: 0.52']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, in Manhattan\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.01', 'neutral: 0.23', 'entailment: 0.76']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, in Manhattan\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.00', 'neutral: 0.04', 'entailment: 0.95']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, in Manhattan\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.00', 'neutral: 0.10', 'entailment: 0.90']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, who is in NY in Brooklyn\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.02', 'neutral: 0.39', 'entailment: 0.59']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, who is in NY in Brooklyn\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.02', 'neutral: 0.37', 'entailment: 0.62']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, who is in NY in Brooklyn\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.01', 'neutral: 0.14', 'entailment: 0.85']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, who is in NY in Brooklyn\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.01', 'neutral: 0.22', 'entailment: 0.77']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, in the zip code 10010\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.01', 'neutral: 0.33', 'entailment: 0.66']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, in the zip code 10010\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.00', 'neutral: 0.03', 'entailment: 0.96']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, in the zip code 10010\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.00', 'neutral: 0.03', 'entailment: 0.96']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, in the zip code 10010\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.00', 'neutral: 0.09', 'entailment: 0.91']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close to me\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.00', 'neutral: 0.10', 'entailment: 0.90']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close to me\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.01', 'neutral: 0.67', 'entailment: 0.32']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close to me\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.01', 'neutral: 0.20', 'entailment: 0.79']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close to me\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.00', 'neutral: 0.11', 'entailment: 0.89']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close to Columbus Circle\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.00', 'neutral: 0.16', 'entailment: 0.83']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close to Columbus Circle\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.01', 'neutral: 0.20', 'entailment: 0.79']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close to Columbus Circle\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.00', 'neutral: 0.06', 'entailment: 0.94']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, close to Columbus Circle\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.00', 'neutral: 0.08', 'entailment: 0.92']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, around Union Square\n",
      "this text is about something that is relatively near\n",
      "['contradiction: 0.00', 'neutral: 0.17', 'entailment: 0.82']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, around Union Square\n",
      "this text refers to a specific address\n",
      "['contradiction: 0.01', 'neutral: 0.11', 'entailment: 0.88']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, around Union Square\n",
      "this text refers to a specific location\n",
      "['contradiction: 0.00', 'neutral: 0.04', 'entailment: 0.96']\n",
      "\n",
      "I am looking for a physical therapist who specializes in sports injuries, around Union Square\n",
      "this text refers to a relative location\n",
      "['contradiction: 0.00', 'neutral: 0.09', 'entailment: 0.91']\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "hypotheses = {\n",
    "    \"relatively_near\": \"this text is about something that is relatively near\",\n",
    "    \"specific_address\": \"this text refers to a specific address\",\n",
    "    \"specific_location\": \"this text refers to a specific location\",\n",
    "    \"relative_location\": \"this text refers to a relative location\"\n",
    "             }\n",
    "premises = [\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, close by\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, nearby\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, near me\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, in Manhattan\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, who is in NY in Brooklyn\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, in the zip code 10010\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, close to me\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, close to Columbus Circle\",\n",
    "    \"I am looking for a physical therapist who specializes in sports injuries, around Union Square\",\n",
    "]\n",
    "terms = [\"contradiction\", \"neutral\", \"entailment\"]\n",
    "for (premise, (hypothesis_brief, hypothesis)) in product(premises, hypotheses.items()):\n",
    "    \n",
    "    tokens = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "    outputs = model(**tokens)\n",
    "    logits = outputs.logits\n",
    "    # (contradiction, neutral, entailment) = float(logits[0][0]), (logits[0][1]), logits[0][2]\n",
    "    probs = logits.softmax(dim=1)\n",
    "    # print(f\"{logits[0][0]:.3f}\")\n",
    "    print(\"\")\n",
    "    print(premise)\n",
    "    print(hypothesis)\n",
    "    print([f\"{x}: {probs[0][i]:.2f}\" for i, x in enumerate(terms)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd90f9-fe10-4595-bcb8-7dd9de0bf7f9",
   "metadata": {},
   "source": [
    "### Hmm not separating \"relative\" vs \"specific\"\n",
    "I'm seeing both \"specific\" and \"relative\" getting flagged for actual locations (e.g. Union Square) \n",
    "\n",
    "### although better news, for the statement, without any location language, location hypotheses are more neutral \n",
    "So, not consistently, though the strenght is low on entailment here, compared with statements that have locations (relative or specific)\n",
    "```\n",
    "I am looking for a physical therapist who specializes in sports injuries\n",
    "this text is about something that is relatively near\n",
    "['contradiction: 0.24', 'neutral: 0.55', 'entailment: 0.21']\n",
    "\n",
    "I am looking for a physical therapist who specializes in sports injuries\n",
    "this text refers to a specific address\n",
    "['contradiction: 0.03', 'neutral: 0.65', 'entailment: 0.32']\n",
    "\n",
    "I am looking for a physical therapist who specializes in sports injuries\n",
    "this text refers to a specific location\n",
    "['contradiction: 0.05', 'neutral: 0.39', 'entailment: 0.56']\n",
    "\n",
    "I am looking for a physical therapist who specializes in sports injuries\n",
    "this text refers to a relative location\n",
    "['contradiction: 0.06', 'neutral: 0.39', 'entailment: 0.55']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa214c5-13da-487b-ba76-56d23207a21d",
   "metadata": {},
   "source": [
    "# Oh cool idea , to use a cased model fine tuned for NER ! \n",
    "lets try , per recommendation from chatgpt \n",
    "\n",
    "This is particularly a good idea, because these models have continuation labels, yea forgot about that, for multi-token entities.\n",
    "\n",
    "Ah right and per [hf](https://huggingface.co/docs/transformers/en/task_summary#token-classification) , yea there are other than NER token classification, also POS part of speech token classification, which can help suss out the meat , possibly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "532e0142-908b-49d9-96c8-db70a348eb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438e04ca3827431d83f153339cec7f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957975482bd448dba71b91facc96991b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00002d07778d4875951c1297f79bdf57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd598f185bf84a058421551d43014380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Locations: \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "query = \"I am looking for a physical therapist who specializes in sports injuries, close by\"\n",
    "ner_results = nlp(query)\n",
    "\n",
    "location_entities = [entity for entity in ner_results if entity['entity'] in ['B-LOC', 'I-LOC']]\n",
    "locations = \" \".join([query[entity['start']:entity['end']] for entity in location_entities])\n",
    "print(\"Extracted Locations:\", locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "798c5ba2-ed99-4817-88a2-322edd2eba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\")\n",
    "\n",
    "query = \"I am looking for a physical therapist who specializes in sports injuries, close by\"\n",
    "ner_results = nlp(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2ff60f1-32a0-492f-9d8e-f7fda2b7c1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b9f585c-ceff-47e4-b7a0-8efce50b15ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"ner\")\n",
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8528f65d-42da-4bdc-98fc-1a2e370b556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"ner\")\n",
    "query = \"I am looking for a physical therapist who specializes in sports injuries, close by\"\n",
    "preds = classifier(query)\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ee9429e-87a6-4b75-9e96-33a853d72cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c2f95-3631-4909-8646-1b08f604a877",
   "metadata": {},
   "source": [
    "Ahh ok this is probably blank, because no location entities here?? lets try another, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b4bf048-2eca-42ea-a13c-c328284f26fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-LOC', 'score': 0.9918, 'index': 15, 'word': 'Union', 'start': 81, 'end': 86}\n",
      "{'entity': 'I-LOC', 'score': 0.9982, 'index': 16, 'word': 'Square', 'start': 87, 'end': 93}\n",
      "{'entity': 'I-LOC', 'score': 0.9884, 'index': 21, 'word': 'Columbus', 'start': 111, 'end': 119}\n",
      "{'entity': 'I-LOC', 'score': 0.998, 'index': 22, 'word': 'Circle', 'start': 120, 'end': 126}\n",
      "{'entity': 'I-LOC', 'score': 0.9934, 'index': 31, 'word': 'Central', 'start': 158, 'end': 165}\n",
      "{'entity': 'I-LOC', 'score': 0.9975, 'index': 32, 'word': 'Park', 'start': 166, 'end': 170}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"ner\")\n",
    "query = \"I am looking for a physical therapist who specializes in sports injuries, around Union Square, or perhaps near Columbus Circle, or say near the south side of Central Park, or maybe just somewhere anywhere near me \"\n",
    "\n",
    "preds = classifier(query)\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f6b6b-b7e7-4dc4-9d70-01ac4e62d0b9",
   "metadata": {},
   "source": [
    "Ok that's cool because this seems to be pretty good at picking out specific geographic locations and ignore relative ones. \n",
    "\n",
    "How about street addresses ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ebe661e-ca9a-4ea8-9456-f231746dc154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-LOC', 'score': 0.8308, 'index': 8, 'word': '14th', 'start': 21, 'end': 25}\n",
      "{'entity': 'I-LOC', 'score': 0.9737, 'index': 13, 'word': 'Broadway', 'start': 36, 'end': 44}\n",
      "{'entity': 'I-LOC', 'score': 0.7358, 'index': 21, 'word': '59', 'start': 71, 'end': 73}\n",
      "{'entity': 'I-LOC', 'score': 0.749, 'index': 22, 'word': '##th', 'start': 73, 'end': 75}\n",
      "{'entity': 'I-LOC', 'score': 0.9923, 'index': 25, 'word': 'Central', 'start': 87, 'end': 94}\n",
      "{'entity': 'I-LOC', 'score': 0.9966, 'index': 26, 'word': 'Park', 'start': 95, 'end': 99}\n",
      "{'entity': 'I-LOC', 'score': 0.9964, 'index': 27, 'word': 'West', 'start': 100, 'end': 104}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"ner\")\n",
    "query = \"I'm on the corner of 14th stret and Broadway and I am trying to get to 59th street and Central Park West ok how can I travel?\"\n",
    "\n",
    "preds = classifier(query)\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f568292-4f3f-45ba-854d-c0d789dab8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
