{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f474cd80-c3bc-45bd-8888-0c7eca9e0298",
   "metadata": {},
   "source": [
    "## thinking through multi concept queries\n",
    "\n",
    "Let's say we have a system where  someone can free query about medical practictioners , providers, and someone has a query like \n",
    "\n",
    "> \"I am looking for a physical therapist who specializes in sports injuries, near Manhattan near SoHo\"\n",
    "\n",
    "Here, we have both medical and location concepts at once.\n",
    "\n",
    "I got an interesting initial suggestion from ChatGPT to try using `spacy` for entity extraction, to cut out the location information and set everything else as medical. Interesting idea. Trying it here, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f532fddb-e3df-4f5b-9649-c293b165a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "query = \"I am looking for a physical therapist who specializes in sports injuries, near Manhattan near SoHo\"\n",
    "doc = nlp(query)\n",
    "\n",
    "medical_concept = []\n",
    "location_concept = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ in [\"GPE\", \"LOC\"]:  # Geopolitical Entity, Location\n",
    "        location_concept.append(ent.text)\n",
    "    else:\n",
    "        medical_concept.append(ent.text)\n",
    "\n",
    "medical_concept_str = \" \".join(medical_concept)\n",
    "location_concept_str = \" \".join(location_concept)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bd290d-97c4-4fa4-8153-9c0407fe695c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], ['Manhattan', 'SoHo'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "medical_concept,  location_concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0806e9-317f-4175-b0ca-b9e44f9e1c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Manhattan, SoHo)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7cede4-2e81-4ab8-928e-81ee782eb613",
   "metadata": {},
   "source": [
    "Okay so that was an interesting idea, but looks like I ought to fill `medical_concept` with everything else even if it is not in `doc.ents` , but also just in the initial query since here `medical_concept` is empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dadd484-d27b-4a9f-ac8e-ac382132c3a8",
   "metadata": {},
   "source": [
    "### Anyway, looking around, also seeing a specialized medical project actually.\n",
    "\n",
    "https://github.com/allenai/scispacy\n",
    "\n",
    "ok , trying out, \n",
    "```\n",
    "pip install scispacy\n",
    "```\n",
    "\n",
    "\n",
    "and perhaps?  \n",
    "```\n",
    "pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558bcf75-2b03-4ab1-a372-fed8049e5a22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e1094d-ad12-40d6-84e1-7562e687861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "query = \"I am looking for some carbonara pasta , near Manhattan near NoHo\"\n",
    "doc = nlp(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80eda90b-fbff-4c51-b25b-3f4208c93e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Manhattan, NoHo)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a8c54-e6c6-440d-9d5e-51dfbe61b463",
   "metadata": {},
   "source": [
    "# 2024-06-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea745a83-9671-47a5-bdc4-1a621e239bed",
   "metadata": {},
   "source": [
    "## try out the zero shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db4ce08-f831-4bc8-b362-c2c27f4e79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load Hugging Face pipeline for zero-shot classification\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "query = \"I am looking for a physical therapist who specializes in sports injuries, close by\"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"current location\", \"physical location\", \"explicit location\"]\n",
    "classification = classifier(query, candidate_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180c776a-c1b1-49e9-81c6-4fe4a067030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michal/opt/miniconda3/envs/pandars310/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8922ff-7215-4442-859b-e6321ce264f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries, close by',\n",
       " 'labels': ['physical location', 'current location', 'explicit location'],\n",
       " 'scores': [0.4983280599117279, 0.25559571385383606, 0.24607622623443604]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc88b0-4215-4771-bfb6-6dffa8e94004",
   "metadata": {},
   "source": [
    "### lets try other classes , maybe for better results  ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec07452-8c4d-4bba-a38d-957dc8d350b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries, close by',\n",
       " 'labels': ['relative location', 'explicit location'],\n",
       " 'scores': [0.811715841293335, 0.18828414380550385]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries, close by\"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"relative location\", \"explicit location\"]\n",
    "classification = classifier(query, candidate_labels)\n",
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f91140fa-c5d1-4826-91ea-c2c07fc9c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries, close by',\n",
       " 'labels': ['relative location', 'explicit location', 'no location provided'],\n",
       " 'scores': [0.8051754236221313, 0.18676704168319702, 0.008057523518800735]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries, close by\"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"relative location\", \"explicit location\", \"no location provided\"]\n",
    "classification = classifier(query, candidate_labels)\n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ef46a-56f8-4570-8dfb-babbc3a59656",
   "metadata": {},
   "source": [
    "Ok this looks promising !?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa71396-6ac4-4af2-ac0b-e612ac339d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries',\n",
       " 'labels': ['explicit location', 'relative location', 'no location provided'],\n",
       " 'scores': [0.6577290892601013, 0.2819722890853882, 0.060298554599285126]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries\"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"relative location\", \"explicit location\", \"no location provided\"]\n",
    "classification = classifier(query, candidate_labels)\n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0febc-20f2-4346-83ee-e6d3c6e1a798",
   "metadata": {},
   "source": [
    "Haha yea that was too good to be true . This is probably difficult to use negation in a class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a18a997e-a5a2-4ae6-a969-05fd7d1d155a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries',\n",
       " 'labels': ['explicit location', 'ambiguous location', 'relative location'],\n",
       " 'scores': [0.5178123712539673, 0.2601984441280365, 0.22198916971683502]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries\"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"relative location\", \"explicit location\", \"ambiguous location\"]\n",
    "classification = classifier(query, candidate_labels)\n",
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6753114-fe4b-4fcf-8bb2-3cbd0a2becd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ZeroShotClassificationPipeline in module transformers.pipelines.zero_shot_classification object:\n",
      "\n",
      "class ZeroShotClassificationPipeline(transformers.pipelines.base.ChunkPipeline)\n",
      " |  ZeroShotClassificationPipeline(args_parser=<transformers.pipelines.zero_shot_classification.ZeroShotClassificationArgumentHandler object at 0x7fad122e8b80>, *args, **kwargs)\n",
      " |  \n",
      " |  NLI-based zero-shot classification pipeline using a `ModelForSequenceClassification` trained on NLI (natural\n",
      " |  language inference) tasks. Equivalent of `text-classification` pipelines, but these models don't require a\n",
      " |  hardcoded number of potential classes, they can be chosen at runtime. It usually means it's slower but it is\n",
      " |  **much** more flexible.\n",
      " |  \n",
      " |  Any combination of sequences and labels can be passed and each combination will be posed as a premise/hypothesis\n",
      " |  pair and passed to the pretrained model. Then, the logit for *entailment* is taken as the logit for the candidate\n",
      " |  label being valid. Any NLI model can be used, but the id of the *entailment* label must be included in the model\n",
      " |  config's :attr:*~transformers.PretrainedConfig.label2id*.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  >>> from transformers import pipeline\n",
      " |  \n",
      " |  >>> oracle = pipeline(model=\"facebook/bart-large-mnli\")\n",
      " |  >>> oracle(\n",
      " |  ...     \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
      " |  ...     candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
      " |  ... )\n",
      " |  {'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}\n",
      " |  \n",
      " |  >>> oracle(\n",
      " |  ...     \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
      " |  ...     candidate_labels=[\"english\", \"german\"],\n",
      " |  ... )\n",
      " |  {'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['english', 'german'], 'scores': [0.814, 0.186]}\n",
      " |  ```\n",
      " |  \n",
      " |  Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)\n",
      " |  \n",
      " |  This NLI pipeline can currently be loaded from [`pipeline`] using the following task identifier:\n",
      " |  `\"zero-shot-classification\"`.\n",
      " |  \n",
      " |  The models that this pipeline can use are models that have been fine-tuned on an NLI task. See the up-to-date list\n",
      " |  of available models on [huggingface.co/models](https://huggingface.co/models?search=nli).\n",
      " |  \n",
      " |  Arguments:\n",
      " |      model ([`PreTrainedModel`] or [`TFPreTrainedModel`]):\n",
      " |          The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from\n",
      " |          [`PreTrainedModel`] for PyTorch and [`TFPreTrainedModel`] for TensorFlow.\n",
      " |      tokenizer ([`PreTrainedTokenizer`]):\n",
      " |          The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from\n",
      " |          [`PreTrainedTokenizer`].\n",
      " |      modelcard (`str` or [`ModelCard`], *optional*):\n",
      " |          Model card attributed to the model for this pipeline.\n",
      " |      framework (`str`, *optional*):\n",
      " |          The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      " |          installed.\n",
      " |  \n",
      " |          If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      " |          both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      " |          provided.\n",
      " |      task (`str`, defaults to `\"\"`):\n",
      " |          A task-identifier for the pipeline.\n",
      " |      num_workers (`int`, *optional*, defaults to 8):\n",
      " |          When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number of\n",
      " |          workers to be used.\n",
      " |      batch_size (`int`, *optional*, defaults to 1):\n",
      " |          When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of\n",
      " |          the batch to use, for inference this is not always beneficial, please read [Batching with\n",
      " |          pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching) .\n",
      " |      args_parser ([`~pipelines.ArgumentHandler`], *optional*):\n",
      " |          Reference to the object in charge of parsing supplied pipeline parameters.\n",
      " |      device (`int`, *optional*, defaults to -1):\n",
      " |          Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, a positive will run the model on\n",
      " |          the associated CUDA device id. You can pass native `torch.device` or a `str` too.\n",
      " |      binary_output (`bool`, *optional*, defaults to `False`):\n",
      " |          Flag indicating if the output the pipeline should happen in a binary format (i.e., pickle) or as raw text.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ZeroShotClassificationPipeline\n",
      " |      transformers.pipelines.base.ChunkPipeline\n",
      " |      transformers.pipelines.base.Pipeline\n",
      " |      transformers.pipelines.base._ScikitCompat\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, sequences: Union[str, List[str]], *args, **kwargs)\n",
      " |      Classify the sequence(s) given as inputs. See the [`ZeroShotClassificationPipeline`] documentation for more\n",
      " |      information.\n",
      " |      \n",
      " |      Args:\n",
      " |          sequences (`str` or `List[str]`):\n",
      " |              The sequence(s) to classify, will be truncated if the model input is too large.\n",
      " |          candidate_labels (`str` or `List[str]`):\n",
      " |              The set of possible class labels to classify each sequence into. Can be a single label, a string of\n",
      " |              comma-separated labels, or a list of labels.\n",
      " |          hypothesis_template (`str`, *optional*, defaults to `\"This example is {}.\"`):\n",
      " |              The template used to turn each label into an NLI-style hypothesis. This template must include a {} or\n",
      " |              similar syntax for the candidate label to be inserted into the template. For example, the default\n",
      " |              template is `\"This example is {}.\"` With the candidate label `\"sports\"`, this would be fed into the\n",
      " |              model like `\"<cls> sequence to classify <sep> This example is sports . <sep>\"`. The default template\n",
      " |              works well in many cases, but it may be worthwhile to experiment with different templates depending on\n",
      " |              the task setting.\n",
      " |          multi_label (`bool`, *optional*, defaults to `False`):\n",
      " |              Whether or not multiple candidate labels can be true. If `False`, the scores are normalized such that\n",
      " |              the sum of the label likelihoods for each sequence is 1. If `True`, the labels are considered\n",
      " |              independent and probabilities are normalized for each candidate by doing a softmax of the entailment\n",
      " |              score vs. the contradiction score.\n",
      " |      \n",
      " |      Return:\n",
      " |          A `dict` or a list of `dict`: Each result comes as a dictionary with the following keys:\n",
      " |      \n",
      " |          - **sequence** (`str`) -- The sequence for which this is the output.\n",
      " |          - **labels** (`List[str]`) -- The labels sorted by order of likelihood.\n",
      " |          - **scores** (`List[float]`) -- The probabilities for each of the labels.\n",
      " |  \n",
      " |  __init__(self, args_parser=<transformers.pipelines.zero_shot_classification.ZeroShotClassificationArgumentHandler object at 0x7fad122e8b80>, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  postprocess(self, model_outputs, multi_label=False)\n",
      " |      Postprocess will receive the raw outputs of the `_forward` method, generally tensors, and reformat them into\n",
      " |      something more friendly. Generally it will output a list or a dict or results (containing just strings and\n",
      " |      numbers).\n",
      " |  \n",
      " |  preprocess(self, inputs, candidate_labels=None, hypothesis_template='This example is {}.')\n",
      " |      Preprocess will take the `input_` of a specific pipeline and return a dictionary of everything necessary for\n",
      " |      `_forward` to run properly. It should contain at least one tensor, but might have arbitrary other items.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  entailment_id\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from transformers.pipelines.base.ChunkPipeline:\n",
      " |  \n",
      " |  get_iterator(self, inputs, num_workers: int, batch_size: int, preprocess_params, forward_params, postprocess_params)\n",
      " |  \n",
      " |  run_single(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from transformers.pipelines.base.Pipeline:\n",
      " |  \n",
      " |  check_model_type(self, supported_models: Union[List[str], dict])\n",
      " |      Check if the model class is in supported by the pipeline.\n",
      " |      \n",
      " |      Args:\n",
      " |          supported_models (`List[str]` or `dict`):\n",
      " |              The list of models supported by the pipeline, or a dictionary with model class values.\n",
      " |  \n",
      " |  device_placement(self)\n",
      " |      Context Manager allowing tensor allocation on the user-specified device in framework agnostic way.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Context manager\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      ```python\n",
      " |      # Explicitly ask for tensor allocation on CUDA device :0\n",
      " |      pipe = pipeline(..., device=0)\n",
      " |      with pipe.device_placement():\n",
      " |          # Every framework specific tensor allocation will be done on the request device\n",
      " |          output = pipe(...)\n",
      " |      ```\n",
      " |  \n",
      " |  ensure_tensor_on_device(self, **inputs)\n",
      " |      Ensure PyTorch tensors are on the specified device.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs (keyword arguments that should be `torch.Tensor`, the rest is ignored):\n",
      " |              The tensors to place on `self.device`.\n",
      " |          Recursive on lists **only**.\n",
      " |      \n",
      " |      Return:\n",
      " |          `Dict[str, torch.Tensor]`: The same as `inputs` but on the proper device.\n",
      " |  \n",
      " |  forward(self, model_inputs, **forward_params)\n",
      " |  \n",
      " |  get_inference_context(self)\n",
      " |  \n",
      " |  iterate(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n",
      " |  \n",
      " |  run_multi(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
      " |  \n",
      " |  save_pretrained(self, save_directory: str, safe_serialization: bool = True)\n",
      " |      Save the pipeline's model and tokenizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          save_directory (`str`):\n",
      " |              A path to the directory where to saved. It will be created if it doesn't exist.\n",
      " |          safe_serialization (`str`):\n",
      " |              Whether to save the model using `safetensors` or the traditional way for PyTorch or Tensorflow.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from transformers.pipelines.base.Pipeline:\n",
      " |  \n",
      " |  default_input_names = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from transformers.pipelines.base._ScikitCompat:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7273189-df9a-48e2-8d68-3cc96d7b142c",
   "metadata": {},
   "source": [
    "hmm try `multi_label=True` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c895de89-5838-4d33-94db-980be47d288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries',\n",
       " 'labels': ['explicit location', 'relative location', 'no location provided'],\n",
       " 'scores': [0.64714115858078, 0.3713032305240631, 0.004426070488989353]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries\"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"relative location\", \"explicit location\", \"no location provided\"]\n",
    "classification = classifier(query, candidate_labels, multi_label=True)\n",
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "836e1933-dd8e-49db-85d8-e647e860f468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0228704595938325"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(classification[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66aad057-ab65-4441-aff7-d345300de2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries, near Manhattan near SoHo',\n",
       " 'labels': ['relative location', 'explicit location', 'no location provided'],\n",
       " 'scores': [0.9820536971092224, 0.9324496388435364, 0.00030656083254143596]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries, near Manhattan near SoHo\"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"relative location\", \"explicit location\", \"no location provided\"]\n",
    "classification = classifier(query, candidate_labels, multi_label=True)\n",
    "classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89a3986b-9a5d-451d-81c6-7c4f7ed39b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries, in Manhattan ',\n",
       " 'labels': ['relative location', 'explicit location', 'no location provided'],\n",
       " 'scores': [0.9801641702651978, 0.923812210559845, 0.0002362721279496327]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries, in Manhattan \"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"relative location\", \"explicit location\", \"no location provided\"]\n",
    "classification = classifier(query, candidate_labels, multi_label=True)\n",
    "classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fac562d-b9fb-4ea0-97d4-136bafb3699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries today ',\n",
       " 'labels': ['explicit location', 'relative location', 'no location provided'],\n",
       " 'scores': [0.8038725256919861, 0.41341912746429443, 0.0036620250903069973]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries today \"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"relative location\", \"explicit location\", \"no location provided\"]\n",
    "classification = classifier(query, candidate_labels, multi_label=True)\n",
    "classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a2afd9e-dc20-4ef4-b05c-c70b16ae4e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries today ',\n",
       " 'labels': ['athletic',\n",
       "  'medical',\n",
       "  'rehabilitation',\n",
       "  'business',\n",
       "  'education',\n",
       "  'culinary',\n",
       "  'music'],\n",
       " 'scores': [0.9634179472923279,\n",
       "  0.5759478807449341,\n",
       "  0.4954245984554291,\n",
       "  0.0016168535221368074,\n",
       "  4.726956467493437e-05,\n",
       "  4.686843021772802e-05,\n",
       "  4.063392771058716e-05]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries today \"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"medical\", \"culinary\", \"business\", \"education\", \"athletic\", \"music\", \"rehabilitation\"]\n",
    "classification = classifier(query, candidate_labels, multi_label=True)\n",
    "classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f94fe3-561e-4218-a84c-29857bfcdd49",
   "metadata": {},
   "source": [
    "Ok well the simple categorization works, just not really the location part here. hmm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6267b64-5fe7-4d6e-8155-dbcea6432dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes in sports injuries today ',\n",
       " 'labels': ['a location is provided', 'there is no location provided'],\n",
       " 'scores': [0.6782494783401489, 0.006060502957552671]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes in sports injuries today \"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"a location is provided\", \"there is no location provided\"]\n",
    "classification = classifier(query, candidate_labels, multi_label=True)\n",
    "classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3632e60-819c-4ca9-a0a3-0c18c2512b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I am looking for a physical therapist who specializes with sports injuries today ',\n",
       " 'labels': ['a location is provided', 'there is no location provided'],\n",
       " 'scores': [0.6726811528205872, 0.006378599908202887]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I am looking for a physical therapist who specializes with sports injuries today \"\n",
    "\n",
    "# Predefined location-related intents\n",
    "candidate_labels = [\"a location is provided\", \"there is no location provided\"]\n",
    "classification = classifier(query, candidate_labels, multi_label=True)\n",
    "classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492b24c-b826-4173-8ba1-067c96202263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d7614d8-2400-4b04-ac64-6782a10ef911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fad19e0fd30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed41b4-b40d-4470-add8-1457bdeab7b6",
   "metadata": {},
   "source": [
    "# 2024-06-15\n",
    "\n",
    "look at these concepts again actually \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2b95857-9752-4952-9a7e-e3ab20a0caa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(I am looking for some carbonara pasta , near Manhattan near NoHo,\n",
       " (Manhattan, NoHo))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc, doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "387e810d-dd3c-4304-b113-7420c8476bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Manhattan, SoHo, philadelphia, kansas, nyc,, 1st avenue, 39th, 111)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for ent in doc.ents:    \\n    if ent.label_ in [\"GPE\", \"LOC\"]:  # Geopolitical Entity, Location\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "query = \"ok,  Manhattan near SoHo, philadelphia pa, kansas, nyc, 1st avenue and 39th street, 111 pilot road,\"\n",
    "doc = nlp(query)\n",
    "print(doc.ents)\n",
    "\n",
    "\"\"\"for ent in doc.ents:    \n",
    "    if ent.label_ in [\"GPE\", \"LOC\"]:  # Geopolitical Entity, Location\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00d20a60-4461-4b84-b742-2ed46c3581fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ok,  Manhattan near SoHo, philadelphia pa, kansas, nyc, 1st avenue and 39th street, 111 pilot road,,\n",
       " [Manhattan],\n",
       " 384,\n",
       " 'GPE',\n",
       " 'Manhattan')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = doc.ents[0]\n",
    "x.doc, x.ents, x.label, x.label_, x.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f4263-20ad-481d-b803-d9cfaf8a84c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
